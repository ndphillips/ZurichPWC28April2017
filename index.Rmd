---
title       : FFTrees
subtitle    : Creating, visualizing, and implementing fast and frugal decision trees
author      : Nathaniel Phillips, University of Basel
job         : Reading Group, PWC, Zurich
framework   : io2012        # {io2012, html5slides, shower, dzslides, ...}
highlighter : highlight.js  # {highlight.js, prettify, highlight}
hitheme     : tomorrow      # 
widgets     : []            # {mathjax, quiz, bootstrap}
mode        : selfcontained # {standalone, draft}
knit        : slidify::knit2slides
bibliography : bibliography.bib
---



```{r, echo = FALSE, eval = TRUE, message = FALSE}
load("data/BaselR_FFTrees.RData")
load("data/forensictrees.RData")
load("data/BaselR_FFTrees.RData")
load("data/forensictrees.RData")
library(FFTrees)
library(knitr)
opts_chunk$set(echo=TRUE, warning=FALSE, message=FALSE, fig.retina = 2)
source("r/helper.R")
```

---&twocol

***=left
### Cook County Hospital, 1996


```{r, fig.margin = TRUE, echo = FALSE, eval = TRUE, out.width = "100%", fig.align='center'}
knitr::include_graphics(c("images/crowdedemergency.jpg"))
```

- 250,000 patients per year, Not enough space, Complete chaos

***=right


"As the city’s principal public hospital, Cook County was the place of last resort for the hundreds of thousands of Chicagoans without health insurance. Resources were stretched to the limit. The hospital’s cavernous wards were built for another century. There were no private rooms, and patients were separated by flimsy plywood dividers. There was no cafeteria or private telephone—just a payphone for everyone at the end of the hall. In one possibly apocryphal story, doctors once trained a homeless man to do routine lab tests because there was no one else available." Malcolm Gladwell, Blink.




--- &twocol

*** =left

### Heart attacks (?)

- **Coronary care bed** ($2K a night + 3 day stay) or **Regular bed**
- Goal: Send true heart attacks to the coronary care, others to a normal bed.

### Multiple, uncertain measures

- Electrocardiogram (ECG), Blood pressure, Stethoscope, How long? During exercise? History? Cholesterol? Drugs?

### Problem

- Doctors make individual, idiosyncratic decisions.
- Very high false positive rate -> High costs, low space.

*** =right

```{r , fig.margin = TRUE, echo = FALSE, out.width = "80%", fig.align='center'}
knitr::include_graphics(c("images/paindecision.png"))
```


---

### Classic prediction problem

- Many cues (aka predictors, features), binary criterion

```{r , fig.margin = TRUE, echo = FALSE, out.width = "100%", fig.align='center'}
knitr::include_graphics(c("images/datadiagram.png"))
```

### Options

- Doctor's intuition -> Was not working well
- Algorithm -> A Decision tree


--- &twocol

## Decision Trees

***=left

#### Definition

- A decision tree is a set of sequential, heirchical, non-compensatory rules.
- A fast and frugal tree (FFT) is a decision tree with exactly two branches from each node, where one, or both, of the branches are exit branches (Martignon et al., 2008)

#### Descriptive Uses

- Inference (Gigerenzer & Goldstein, 1996)
- Judge's bailing decisions (Dhami, 2003)

#### Prescriptive Uses

- Terrorist attacks (Garcia, 2016)
- Bank failure (Aikman et al., 2014; Neth et al., 2014)


***=right

```{r , fig.margin = TRUE, echo = FALSE, out.width = "100%", fig.align='center', message = FALSE, echo = FALSE}
knitr::include_graphics(c("images/nethfft.png"))
```

Neth et al. (2014). "Homo heuristicus in the financial world".



---&twocol

## Emergency Room Solution: a fast and frugal tree (FFT)

***=left

- A fast and frugal decision tree (FFT) developed by Lee Goldman.
- Doctor's intuition accuracy: 75-90%, Decision tree accuracy: 95%
- Tree had far fewer false-positives and substantial cost savings
- One of the great successs stories of an algorithm used in practice.

***=right

```{r , fig.margin = TRUE, echo = FALSE, out.width = "70%", fig.align='center'}
#plot(heart.fft, stats = FALSE, main = "Example FFT")
knitr::include_graphics(c("images/cooktree.png"))
```



---

## Why use a simple algorithm like an FFT?

| | Complex| Simple |
|:---------|:----|:-----|
|     Example|    Regression, Random Forests, Bayes|Fast and Frugal Tree (FFT)|
|     Information Requirements|    High|Low     |
| Cost of use | High | Low |
|     Search|    Comprehensive|Sequential     |
|     Speed|    Slow|Fast     |
| Transparency, ease of use| Medium or Low| High|
| Accuracy | Depends | Depends |

---&twocol
## FFTrees

***=left

- Problem: While there are many packages for creating non-frugal decision trees (like `rpart()`), no such tool exists for fast and frugal trees.

- Solution: `FFTrees` An easy-to-use R package to create, visualize, and implement fast and frugal decision trees.

<br>
<div style="text-align:left"><font size="1"> Phillips et al. (under review). FFTrees: An R package to create, visualize, and implement fast and frugal decision trees</font></div>


***=right


```{r , fig.margin = TRUE, echo = FALSE, out.width = "80%", fig.align='center', message = FALSE, echo = FALSE}
 knitr::include_graphics(c("images/FFTrees_Logo.jpg"))
```


---

## Heart Disease Data

```{r, echo = FALSE, message = FALSE}
library(FFTrees)
knitr::kable(head(heartdisease))
```

- Goal: Predict diagnosis as a function of cues.
- Regression: 6 significant cues (sex, cp, thalach, exang, oldpeak, ca)


---

## 3 Steps to creating FFTs with FFTrees

```{r, eval = FALSE}
# Step 0: Install FFTrees (v.1.2.0)
install.packages("FFTrees")

# Step 1: Load the package
library("FFTrees")

# Step 2: Create an fft decision model with FFTrees
heart.fft <- FFTrees(formula = diagnosis ~.,
                       data = heartdisease)
```

## Demo


---&twocol

***=left

## How trees are built with FFTrees

1. For each cue, calculate a decision threshold that maximizes accuracy *ignoring all other cues*.
2. Rank order cues by their maximum accuracy.
3. Select the top N (i.e., 4) most accurate cues
    - If any lower levels contain less than X\% (e.g., 10\%) of the data, remove them.
4. Select the exit structure with the highest accuracy.

***=right

```{r, echo = FALSE}
# Age thresholds to test
ages.to.test <- seq(20, to = 90, by = 5)

# Calculate balanced accuracy for each threshold
y <- sapply(ages.to.test, FUN = function(x) {
  
  decisions <- heartdisease$age > x
  
  sens <- mean(decisions[heartdisease$diagnosis == 1] == 1)
  spec <- mean(decisions[heartdisease$diagnosis == 0] == 0)
  
  bacc <- (sens + spec) / 2
  
  return(bacc)

})

plot(ages.to.test, y, 
     type = "b", 
     xlab = "age threshold", 
     ylab = "balanced accuracy (bacc)", ylim = c(.5, .7),
     main = "Finding a threshold for Age")

grid()

text(55, 
     y[ages.to.test == 55], 
     labels = paste("age = 55, bacc = ", round(y[ages.to.test == 55], 2)), 
     pos = 3)

```




---

### Prediction model competition

- 100 50/50 cross validation simulations on the heartdisease dataset.

```{r , fig.margin = TRUE, echo = FALSE, out.width = "70%", fig.align='center', message = FALSE, echo = FALSE}
knitr::include_graphics(c("images/crossvalidation.jpg"))
```




---

### Prediction model competition

```{r , fig.margin = TRUE, echo = FALSE, out.width = "95%", fig.align='center', message = FALSE, echo = FALSE, fig.width = 12, fig.height = 6}
library(yarrr)
par(mfrow = c(1, 2))
pirateplot(data = data.frame("Random" = rnorm(100, mean = .5, sd = .01),
                            "FFTrees" = heart.fff$tree.sim$bacc.train, 
                             "rpart" = heart.fff$cart.sim$bacc.train, 
                             "lm" = heart.fff$lr.sim$bacc.train, 
                             "rForest" = heart.fff$rf.sim$bacc.train),
           ylim = c(.5, 1), yaxt = "n", gl = seq(.5, 1, .05),  gl.lwd = c(.75, .25),
           main = "Heartdisease - Fitting", ylab = "Balanced Accuracy", sortx = "s", xlab = "Model")
axis(2, at = seq(.5, 1, .1), las = 1)

rect(-1000, -1000, 1000, 100, col = "white", border = NA)

pirateplot(data = data.frame("Random" = rnorm(100, mean = .5, sd = .01),
                              "FFTrees" = heart.fff$tree.sim$bacc.test, 
                             "rpart" = heart.fff$cart.sim$bacc.test, 
                             "lm" = heart.fff$lr.sim$bacc.test, 
                             "rForest" = heart.fff$rf.sim$bacc.test),
           ylim = c(.5, 1), yaxt = "n", gl = seq(.5, 1, .05),  gl.lwd = c(.75, .25),
           main = "Heartdisease - Prediction", ylab = "Balanced Accuracy", sortx = "s", xlab = "Model")
axis(2, at = seq(.5, 1, .1), las = 1)
rect(-1000, -1000, 1000, 100, col = "white", border = NA)
```


---

### Prediction model competition

```{r , fig.margin = TRUE, echo = FALSE, out.width = "95%", fig.align='center', message = FALSE, echo = FALSE, fig.width = 12, fig.height = 6}
library(yarrr)
par(mfrow = c(1, 2))
pirateplot(data = data.frame("Random" = rnorm(100, mean = .5, sd = .01),
                            "FFTrees" = heart.fff$tree.sim$bacc.train, 
                             "rpart" = heart.fff$cart.sim$bacc.train, 
                             "lm" = heart.fff$lr.sim$bacc.train, 
                             "rForest" = heart.fff$rf.sim$bacc.train),
           ylim = c(.5, 1), yaxt = "n", gl = seq(.5, 1, .05),  gl.lwd = c(.75, .25),
           main = "Heartdisease - Fitting", ylab = "Balanced Accuracy", sortx = "s", xlab = "Model")
axis(2, at = seq(.5, 1, .1), las = 1)

pirateplot(data = data.frame("Random" = rnorm(100, mean = .5, sd = .01),
                              "FFTrees" = heart.fff$tree.sim$bacc.test, 
                             "rpart" = heart.fff$cart.sim$bacc.test, 
                             "lm" = heart.fff$lr.sim$bacc.test, 
                             "rForest" = heart.fff$rf.sim$bacc.test),
           ylim = c(.5, 1), yaxt = "n", gl = seq(.5, 1, .05),  gl.lwd = c(.75, .25),
           main = "Heartdisease - Prediction", ylab = "Balanced Accuracy", sortx = "s", xlab = "Model")
axis(2, at = seq(.5, 1, .1), las = 1)
rect(-1000, -1000, 1000, 100, col = "white", border = NA)
```



---

### Prediction model competition

```{r , fig.margin = TRUE, echo = FALSE, out.width = "95%", fig.align='center', message = FALSE, echo = FALSE, fig.width = 12, fig.height = 6}
library(yarrr)
par(mfrow = c(1, 2))
pirateplot(data = data.frame("Random" = rnorm(100, mean = .5, sd = .01),
                            "FFTrees" = heart.fff$tree.sim$bacc.train, 
                             "rpart" = heart.fff$cart.sim$bacc.train, 
                             "lm" = heart.fff$lr.sim$bacc.train, 
                             "rForest" = heart.fff$rf.sim$bacc.train),
           ylim = c(.5, 1), yaxt = "n", gl = seq(.5, 1, .05),  gl.lwd = c(.75, .25),
           main = "Heartdisease - Fitting", ylab = "Balanced Accuracy", sortx = "s", xlab = "Model")
axis(2, at = seq(.5, 1, .1), las = 1)

pirateplot(data = data.frame("Random" = rnorm(100, mean = .5, sd = .01),
                              "FFTrees" = heart.fff$tree.sim$bacc.test, 
                             "rpart" = heart.fff$cart.sim$bacc.test, 
                             "lm" = heart.fff$lr.sim$bacc.test, 
                             "rForest" = heart.fff$rf.sim$bacc.test),
           ylim = c(.5, 1), yaxt = "n", gl = seq(.5, 1, .05),  gl.lwd = c(.75, .25),
           main = "Heartdisease - Prediction", ylab = "Balanced Accuracy", sortx = "s", xlab = "Model")
axis(2, at = seq(.5, 1, .1), las = 1)
```



---&twocol
## Efficiency

***=left

- FFTs are very cheap to implement

- Heart disease data
    - Regression (all cues): $300
    - Heart disease FFT: $123.21

***=right

```{r , fig.margin = TRUE, echo = FALSE, out.width = "100%", fig.align='center', message = FALSE, echo = FALSE}
# knitr::include_graphics(c("images/traintreestats.png"))
```


| cue| cost | description|values |
|:------|:---|:----|:-----|
|     `thal`| $102 | thallium scintigraphy, a nuclear imaging test that measures blood flow|normal (n), fixed defect (fd), reversible defect (rd)     |
|     `cp`| $1 |    Chest pain type| Typical (ta), atypical (aa), non-anginal pain (np), asymptomatic (a)     |
|     `ca`| $101 | Number of major vessels colored by flourosopy, an x-ray imaging tool|0, 1, 2 or 3 |


---&twocol

***=left

## Generalizing FFTrees

- The `FFTrees` package can be used with any dataset with a binary criterion.
- Simulation: 10 diverse datasets taken from the UCI Machine Learning Database.
- FFTrees vs. regression, Naive Bayes, Random Forests and more

### How well can a simple fast and frugal tree predict data?  

***=right

```{r , fig.margin = TRUE, echo = FALSE, out.width = "90%", fig.align='center'}
knitr::include_graphics(c("images/datacollage.png"))
```




---

```{r, eval = FALSE}
mushrooms.fft <- FFTrees(poisonous ~., data = mushrooms)
```


```{r, echo = FALSE, out.width = "55%", dpi = 200, fig.width = 8, fig.height = 7, fig.align = 'center'}
load("data/mushrooms.RData")
plot(mushrooms.fft, main = "Mushroom Toxicity")
```


---

```{r, eval = TRUE}
breast.fft <- FFTrees(diagnosis ~ ., data = breastcancer)
```

```{r, echo = FALSE, out.width = "55%", dpi = 200, fig.width = 8, fig.height = 7, fig.align = 'center'}
plot(breast.fft, main = "Breast Cancer")
```





--- .class #id 
## Speed and frugality


```{r, echo = FALSE, fig.align = 'center', fig.width = 6, fig.height = 6, out.width = "60%", dpi = 200}

data.name <- c("arrhythmia", "audiology", "breast", "bridges", "cmc", "credit", "dermatology", "heart", "occupancy", "yeast")
mcu <- c(1.85, 1.73, 1.39, 2.40, 2.06, 1.9, 1.69, 1.72, 1.92, 1.63)
pci <- c(.99, .98, .86, .76, .79, .88, .95, .88, .68, .82)

plot(mcu, pci, xlim = c(1, 10), ylim = c(0, 1), xlab = "Mean cues used to make a decision", 
     ylab = "Percent of information ignored", pch = 21, col = "white", 
     bg = yarrr::piratepal("basel", trans = .2), cex = 2, main = "FFTrees speed and frugality", xaxt = "n", yaxt = "n", type = "n")
grid()
axis(1, 1:10)
axis(2, seq(0, 1, .2), las = 1)

rect(7, .05, 10, .95, col = yarrr::transparent("white", .2), border = gray(.5, .5))

text(rep(8, length(data.name)), seq(.1, .9, length.out = length(data.name)), labels = data.name, adj = 0)
points(rep(7.5, length(data.name)), seq(.1, .9, length.out = length(data.name)), pch = 21, col = "white", bg = yarrr::piratepal("basel", trans = .2), cex = 2)



```


--- .class #id 
## Speed and frugality


```{r, echo = FALSE, fig.align = 'center', fig.width = 6, fig.height = 6, out.width = "60%", dpi = 200}

data.name <- c("arrhythmia", "audiology", "breast", "bridges", "cmc", "credit", "dermatology", "heart", "occupancy", "yeast")
mcu <- c(1.85, 1.73, 1.39, 2.40, 2.06, 1.9, 1.69, 1.72, 1.92, 1.63)
pci <- c(.99, .98, .86, .76, .79, .88, .95, .88, .68, .82)

plot(mcu, pci, xlim = c(1, 10), ylim = c(0, 1), xlab = "Mean cues used to make a decision", 
     ylab = "Percent of information ignored", pch = 21, col = "white", 
     bg = yarrr::piratepal("basel", trans = .2), cex = 2, main = "FFTrees speed and frugality", xaxt = "n", yaxt = "n")
grid()
axis(1, 1:10)
axis(2, seq(0, 1, .2), las = 1)

rect(7, .05, 10, .95, col = yarrr::transparent("white", .2), border = gray(.5, .5))

text(rep(8, length(data.name)), seq(.1, .9, length.out = length(data.name)), labels = data.name, adj = 0)
points(rep(7.5, length(data.name)), seq(.1, .9, length.out = length(data.name)), pch = 21, col = "white", bg = yarrr::piratepal("basel", trans = .7), cex = 2)

segments(mcu, pci, rep(7.5, length(data.name)), seq(.1, .9, length.out = length(data.name)), col = gray(.5, .2))


```



--- .class #id 
## Prediction accuracy across 10 dasets

```{r , fig.margin = TRUE, echo = FALSE, out.width = "90%", fig.align='center'}
knitr::include_graphics(c("images/simulationagg_c.png"))
```


--- .class #id 

```{r , fig.margin = TRUE, echo = FALSE, out.width = "67%", fig.align='center'}
knitr::include_graphics(c("images/simulationseparate.png"))
```




---&twocol

***=left

### FFTrees Unfriendly Data

- Many cues, weak validity, ind errors

```{r, echo = FALSE, fig.width = 4, fig.height = 4, out.width = "100%"}
## Regression Friendly
plot(1, xlim = c(-60, 60), ylim = c(-60, 60), type = "n", yaxt = "n", 
     xaxt = "n", xlab = "", ylab = "", main = "FFTrees Unfriendly")
# abline(h = 0, lty = 1, col = gray(.5, .5))
# abline(v = 0, lty = 1, col = gray(.5, .5))

circ.fun <- function(x, x.c = 0, y.c = 0, r = 1) {
  
  output <- y.c + sqrt(r ^ 2 - (x - x.c) ^ 2)

  return(output)
    
}


cor.vals <- runif(20, min = .1, max = .3)

points(x = c(seq(-50, 45, length.out = 10), 
             seq(-45, 50, length.out = 10)),
       y = c(circ.fun(seq(-50, 45, length.out = 10), r = 50),
             -circ.fun(seq(-45, 50, length.out = 10), r = 50)), cex = cor.vals * 4)

segments(x0 = seq(-50, 45, length.out = 10), 
       y0 = circ.fun(seq(-50, 45, length.out = 10), r = 50),
       x1 = 0, y1 = 0, col = gray(1 - cor.vals[1:10]))

segments(x0 = seq(-45, 50, length.out = 10), 
       y0 = - circ.fun(seq(-45, 50, length.out = 10), r = 50),
       x1 = 0, y1 = 0, col = gray(1 - cor.vals[11:length(cor.vals)]))

points(0, 0, cex = 4, pch = 21, bg = "white", col = "black")
text(0, 0, labels = "C")
```


***=right

### FFTrees Friendly Data

- Few cues with high validity, dep errors.

```{r, echo = FALSE, fig.width = 4, fig.height = 4, out.width = "100%"}
## FFTrees Friendly
set.seed(125)

plot(1, xlim = c(-60, 60), ylim = c(-60, 60), type = "n", yaxt = "n", 
     xaxt = "n", xlab = "", ylab = "", main = "FFTrees Friendly")
# abline(h = 0, lty = 1, col = gray(.5, .5))
# abline(v = 0, lty = 1, col = gray(.5, .5))

circ.fun <- function(x, x.c = 0, y.c = 0, r = 1) {
  
  output <- y.c + sqrt(r ^ 2 - (x - x.c) ^ 2)

  return(output)
    
}


cor.vals <- c(runif(17, min = 0, max = .3), runif(3, min = .6, max = 1))[sample(20)]

points(x = c(seq(-50, 45, length.out = 10), 
             seq(-45, 50, length.out = 10)),
       y = c(circ.fun(seq(-50, 45, length.out = 10), r = 50),
             -circ.fun(seq(-45, 50, length.out = 10), r = 50)), 
       cex = cor.vals * 4)

segments(x0 = seq(-50, 45, length.out = 10), 
       y0 = circ.fun(seq(-50, 45, length.out = 10), r = 50),
       x1 = 0, y1 = 0, col = gray(1 - cor.vals[1:10]), lwd = cor.vals[1:10] * 3)

segments(x0 = seq(-45, 50, length.out = 10), 
       y0 = - circ.fun(seq(-45, 50, length.out = 10), r = 50),
       x1 = 0, y1 = 0, col = gray(1 - cor.vals[11:length(cor.vals)]), 
       lwd = cor.vals[11:20] * 3)


points(0, 0, cex = 4, pch = 21, bg = "white", col = "black")
text(0, 0, labels = "C")
```


---

### When should I consider an FFT?

```{r , fig.margin = TRUE, echo = FALSE, out.width = "80%", fig.align='center'}
knitr::include_graphics(c("images/shouldiuseanfft.png"))
```


---&twocol

***=left

### Next steps for the FFTrees package

1. Incorporate numerical cue costs in algorithm.
2. Re-write FFT growing code in C++ for speed.
    - Consider simulation based fitting methods.
3. Quantify changes in data over time given a single tree.
    - Can notify user when there is an important change in the data.

***=right

```{r, fig.margin = TRUE, echo = FALSE, out.width = "100%", fig.align='center', message = FALSE,  eval = TRUE}
plot(heart.fft, main = "Heart Disease", decision.names = c("Healthy", "Diseased"))
```


---&twocol
## Collaborators

***=left

- Wolfgang Gaissmaier (University of Konstanz)
- Hansjoerg Neth  (University of Konstanz)
- Jan Woike  (MPI for Human Development)

***=right

```{r , fig.margin = TRUE, echo = FALSE, out.width = "90%", fig.align='center'}
knitr::include_graphics(c("images/collaborators.png"))
```




--- .class #id 

### FFTrees

#### My Links

- This presentation: [https://ndphillips.github.io/ZurichPWC28April2017](https://ndphillips.github.io/ZurichPWC28April2017)
- Website: https://ndphillips.github.io
- Email: Nathaniel.D.Phillips.is@gmail.com

#### Packages

- FFTrees: `install.packages("FFTrees")`
- yarrr: `install.packages("yarrr")`



--- &twocol

*** =left
## FFTrees algorithm

1. Calculate a decision threshold `t` for each cue that maximizes the cue’s balanced accuracy `bacc` in training.

2. Rank cues in order of their maximum balanced accuracy -- select the top N cues. 

3. Creates all possible `2^{N−1}` trees with these cues, using all exit structures.

*** =right

```{r echo = FALSE, fig.align = 'center'}
heartdisease$chol.cut <- cut(heartdisease$chol, breaks = 10)

cutoffs <- seq(min(heartdisease$chol), max(heartdisease$chol), length.out = 10)

vals <- sapply(cutoffs, FUN = function(x) {
  
  acc <- mean(heartdisease$diagnosis[heartdisease$chol >= x]) * .5 +
         mean(heartdisease$diagnosis[heartdisease$chol < x] == FALSE) * .5
  
})


plot(cutoffs, vals, ylab = "bacc", xlab = "Decision Threshold", main = "Cholestorol", type = "b", ylim = c(0, 1))

text(cutoffs, vals, paste(">", round(cutoffs, 0)), pos = 3)

with(subset(heartdisease, diagnosis == 1), 
     points(chol, rep(.9, length(chol)) + rnorm(length(chol), mean = 0, sd = .02), pch = 21, bg = yarrr::transparent("red", .6), col = "white"))

with(subset(heartdisease, diagnosis == 0), 
     points(chol, rep(.8, length(chol)) + rnorm(length(chol), mean = 0, sd = .02), pch = 21, bg = yarrr::transparent("blue", .6), col = "white"))

```



---&twocol

## Complexity vs. Simplicity

***=left

<br>

```{r, eval = TRUE, echo = FALSE, out.width = "100%", fig.align = 'center'}
knitr::include_graphics("images/complexity.jpg")
```

***=right

<br>

```{r, eval = TRUE, echo = FALSE, out.width = "95%", fig.align = 'center'}
knitr::include_graphics("images/decisionsimple.jpg")
```


---

```{r, dpi = 200, out.width = "80%", fig.width = 6, fig.height = 5, echo = FALSE, fig.align = 'center'}
plot(1, xlim = c(0, 100), ylim = c(0, 100), type = "n", 
     xlab = "Complexity", ylab = "Accuracy", main = "Complexity and Accuracy")
grid()
```

---

```{r, dpi = 200, out.width = "80%", fig.width = 6, fig.height = 5, echo = FALSE, fig.align='center'}
plot(1, xlim = c(0, 100), ylim = c(0, 100), type = "n", 
     xlab = "Complexity", ylab = "Accuracy", main = "Complexity and Accuracy")
grid()

points(90, 80, cex = 2)
points(0, 0, cex = 2)
points(50, 50, cex = 2)


text(5, 5, labels = "Random")
text(85, 70, labels = "Random Forests\nSVM")
text(55, 55, labels = "Regression")
```


---

```{r, dpi = 200, out.width = "80%", fig.width = 6, fig.height = 5, echo = FALSE, fig.align='center'}
plot(1, xlim = c(0, 100), ylim = c(0, 100), type = "n", 
     xlab = "Complexity", ylab = "Accuracy", main = "Complexity and Accuracy")
grid()

points(90, 80, cex = 2)
points(0, 0, cex = 2)

text(5, 5, labels = "Random")
text(85, 70, labels = "Random Forests\nSVM")

# points(rep(20, 5), seq(10, 75, length.out = 5), col = "green", pch = 16)

linear <- function(x) {line.fun(alpha = 1, x = x, x1 = 0, y1 = 0, x2 = 90, y2 = 80)}
curve(linear, from = 0, to = 90, ylim = c(0, 100), xlim = c(0, 100), add = TRUE)
```

---

```{r, dpi = 200, out.width = "80%", fig.width = 6, fig.height = 5, echo = FALSE, fig.align='center'}
plot(1, xlim = c(0, 100), ylim = c(0, 100), type = "n", 
     xlab = "Complexity", ylab = "Accuracy", main = "Complexity and Accuracy")
grid()

points(90, 80, cex = 2)
text(5, 5, labels = "Random")
text(85, 70, labels = "Random Forests\nSVM")

slow <- function(x) {line.fun(alpha = .5, x = x, x1 = 0, y1 = 0, x2 = 90, y2 = 80)}
curve(slow, from = 0, to = 90, ylim = c(0, 100), xlim = c(0, 100), add = TRUE)
```

---

```{r, dpi = 200, out.width = "80%", fig.width = 6, fig.height = 5, echo = FALSE, fig.align='center'}
plot(1, xlim = c(0, 100), ylim = c(0, 100), type = "n", 
     xlab = "Complexity", ylab = "Accuracy", main = "Complexity and Accuracy")
grid()

points(90, 80, cex = 2)
text(5, 5, labels = "Random")
text(85, 70, labels = "Random Forests\nSVM")

fast <- function(x) {line.fun(alpha = .05, x = x, x1 = 0, y1 = 0, x2 = 90, y2 = 80)}
curve(fast, from = 0, to = 90, ylim = c(0, 100), xlim = c(0, 100), add = TRUE)
```



